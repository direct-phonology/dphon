<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>dphon.corpus API documentation</title>
<meta name="description" content="Classes for loading document corpora and passing them to an NLP pipeline." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>dphon.corpus</code></h1>
</header>
<section id="section-intro">
<p>Classes for loading document corpora and passing them to an NLP pipeline.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#!/usr/bin/env python
# -*- coding: utf-8 -*-
&#34;&#34;&#34;Classes for loading document corpora and passing them to an NLP pipeline.&#34;&#34;&#34;

import logging
import jsonlines
from abc import ABC, abstractmethod
from collections import OrderedDict
from glob import glob
from pathlib import Path
from typing import Any, Dict, Iterable, Tuple, Union

from rich.progress import Progress, BarColumn, TextColumn, SpinnerColumn

from .console import err_console

# Type for a doc ready to be indexed by spaCy&#39;s `nlp.pipe(as_tuples=True)`:
# (content, metadata) where content is a string and metadata is a dict
DocInfo_T = Tuple[str, Dict[str, Any]]

# Translation table for text content, used for fast text preprocessing
# currently converts all whitespace to `None` (i.e. strips it out)
# and converts some lacunae/missing character markers to fullwidth versions
ALL_WS = &#34;\t\n\x0b\x0c\r\x1c\x1d\x1e\x1f\x85\xa0\u1680\u2000\u2001\u2002\u2003\u2004\u2005\u2006\u2007\u2008\u2009\u200a\u2028\u2029\u202f\u205f\u3000&#34;
WS_NONE = {k: None for k in list(ALL_WS)}
LACUNAE = {&#34;□&#34;: &#34;〼&#34;, &#34;○&#34;: &#34;〇&#34;}
CONVERT: Dict[str, Union[str, None]] = {**WS_NONE, **LACUNAE}
OC_TEXT = str.maketrans(CONVERT)


class CorpusLoader(ABC):
    &#34;&#34;&#34;Abstract base class; implements loading of document corpora.&#34;&#34;&#34;

    filetype: str
    progress: Progress

    def __init__(self) -&gt; None:
        &#34;&#34;&#34;Set up progress tracking.&#34;&#34;&#34;
        self.progress = Progress(
            &#34;[progress.description]{task.description}&#34;,
            SpinnerColumn(),
            TextColumn(&#34;[progress.description]{task.fields[filename]}&#34;),
            BarColumn(bar_width=None),
            &#34;{task.completed}/{task.total}&#34;,
            &#34;[progress.percentage]{task.percentage:&gt;3.1f}%&#34;,
            console=err_console,
            transient=True,
        )

    @abstractmethod
    def __call__(self, paths: Iterable[str]) -&gt; Iterable[DocInfo_T]:
        &#34;&#34;&#34;Load valid files from all paths, returning contents and metadata.

        Output is a single tuple of (contents, metadata) where &#34;contents&#34; is the
        contents of the file as a string and &#34;metadata&#34; is an arbitrary dict.

        One tuple per doc should be returned for consumption by spaCy&#39;s 
        `nlp.pipe(as_tuples=True)`.
        &#34;&#34;&#34;
        raise NotImplementedError

    def _check(self, paths: Iterable[str]) -&gt; Dict[Path, Any]:
        &#34;&#34;&#34;Check each of the provided paths and output a list of valid files.&#34;&#34;&#34;

        # track how many valid files we found, and store valid ones with their
        # metadata for loading
        total = 0
        files = {}

        # try to create a `pathlib.Path` from each expanded path; store it
        # if we succeed so that we can later open the file using it
        for path in paths:
            for file in map(Path, glob(path)):
                if file.is_file() and file.suffix == self.filetype:
                    size = file.stat().st_size
                    files[file] = {&#34;size&#34;: size, &#34;id&#34;: file.stem}
                    total += 1
                    logging.debug(f&#34;found {file.resolve()}, size={size}B&#34;)
                else:
                    logging.warning(
                        f&#34;path {file.resolve()} isn&#39;t a {self.filetype} file&#34;)

        # if no valid files were found, notify the user and exit. otherwise
        # report the total number of files found
        if not total:
            logging.error(&#34;no valid files found&#34;)
            exit(1)
        else:
            logging.debug(f&#34;found {total} total files&#34;)
        return files


class PlaintextCorpusLoader(CorpusLoader):
    &#34;&#34;&#34;Loads documents stored as one or more .txt files.&#34;&#34;&#34;

    filetype = &#34;.txt&#34;

    def __call__(self, paths: Iterable[str]) -&gt; Iterable[DocInfo_T]:
        &#34;&#34;&#34;Load valid files and metadata and yield in order of size, desc.

        All provided paths will be searched, and globs will be expanded, e.g.
        /my/home/dir/*.txt will yield all plaintext files in /my/home/dir/.

        File metadata consists of the file&#39;s name, minus extension (the &#34;stem&#34;)
        and the file size on disk in bytes.

        Args:
            paths: Iterable of .txt file paths to load.

        Yields:
            A tuple of (contents, metadata) for each valid document found.
        &#34;&#34;&#34;

        # sort files by size, largest first, to speed up processing by spaCy
        files = self._check(paths)
        files_by_size = OrderedDict(sorted(files.items(),
                                           key=lambda f: f[1][&#34;size&#34;],
                                           reverse=True))

        # track progress
        task = self.progress.add_task(
            &#34;indexing&#34;, filename=&#34;&#34;, total=len(files))

        # open each file and yield contents with metadata as DocInfo_T
        with self.progress:
            for file, meta in files_by_size.items():
                self.progress.update(task, filename=file.name)
                with file.open(encoding=&#34;utf8&#34;) as contents:
                    logging.debug(
                        f&#34;loaded doc \&#34;{meta[&#39;id&#39;]}\&#34; from {file.resolve()}&#34;)
                    yield contents.read().translate(OC_TEXT), {&#34;id&#34;: meta[&#34;id&#34;]}
                    self.progress.advance(task)


class JsonLinesCorpusLoader(CorpusLoader):
    &#34;&#34;&#34;Loads documents stored as lines in one or more .jsonl files.&#34;&#34;&#34;

    filetype = &#34;.jsonl&#34;

    def __call__(self, paths: Iterable[str]) -&gt; Iterable[DocInfo_T]:
        &#34;&#34;&#34;Parse .jsonl files and yield document text and metadata.

        All provided paths will be searched, and globs will be expanded, e.g.
        /my/home/dir/*.jsonl will yield all jsonlines files in /my/home/dir/.

        Each .jsonl file is assumed to consist of lines where each line is a
        valid JSON object. The only required properties are &#34;id&#34;, a unique name
        for the document, and &#34;text&#34;, the text of the document itself. All
        other properties will be passed through to spaCy.

        Args:
            paths: Iterable of .jsonl file paths to load.

        Yields:
            A tuple of (contents, metadata) for each valid document found.
        &#34;&#34;&#34;

        # track progress
        files = self._check(paths)
        task = self.progress.add_task(
            &#34;indexing&#34;, filename=&#34;&#34;, total=len(files))

        # open each file and yield each line, with all properties except &#34;text&#34;
        # being passed as second element in tuple
        with self.progress:
            for file in files.keys():
                with jsonlines.open(file) as reader:
                    self.progress.update(task, filename=file.name)
                    for doc in reader:
                        meta = {k: v for k, v in doc.items() if k != &#34;text&#34;}
                        logging.debug(
                            f&#34;loaded doc \&#34;{doc[&#39;id&#39;]}\&#34; from {file.resolve()}&#34;)
                        yield doc[&#34;text&#34;].translate(OC_TEXT), meta
                    self.progress.advance(task)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="dphon.corpus.CorpusLoader"><code class="flex name class">
<span>class <span class="ident">CorpusLoader</span></span>
</code></dt>
<dd>
<div class="desc"><p>Abstract base class; implements loading of document corpora.</p>
<p>Set up progress tracking.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CorpusLoader(ABC):
    &#34;&#34;&#34;Abstract base class; implements loading of document corpora.&#34;&#34;&#34;

    filetype: str
    progress: Progress

    def __init__(self) -&gt; None:
        &#34;&#34;&#34;Set up progress tracking.&#34;&#34;&#34;
        self.progress = Progress(
            &#34;[progress.description]{task.description}&#34;,
            SpinnerColumn(),
            TextColumn(&#34;[progress.description]{task.fields[filename]}&#34;),
            BarColumn(bar_width=None),
            &#34;{task.completed}/{task.total}&#34;,
            &#34;[progress.percentage]{task.percentage:&gt;3.1f}%&#34;,
            console=err_console,
            transient=True,
        )

    @abstractmethod
    def __call__(self, paths: Iterable[str]) -&gt; Iterable[DocInfo_T]:
        &#34;&#34;&#34;Load valid files from all paths, returning contents and metadata.

        Output is a single tuple of (contents, metadata) where &#34;contents&#34; is the
        contents of the file as a string and &#34;metadata&#34; is an arbitrary dict.

        One tuple per doc should be returned for consumption by spaCy&#39;s 
        `nlp.pipe(as_tuples=True)`.
        &#34;&#34;&#34;
        raise NotImplementedError

    def _check(self, paths: Iterable[str]) -&gt; Dict[Path, Any]:
        &#34;&#34;&#34;Check each of the provided paths and output a list of valid files.&#34;&#34;&#34;

        # track how many valid files we found, and store valid ones with their
        # metadata for loading
        total = 0
        files = {}

        # try to create a `pathlib.Path` from each expanded path; store it
        # if we succeed so that we can later open the file using it
        for path in paths:
            for file in map(Path, glob(path)):
                if file.is_file() and file.suffix == self.filetype:
                    size = file.stat().st_size
                    files[file] = {&#34;size&#34;: size, &#34;id&#34;: file.stem}
                    total += 1
                    logging.debug(f&#34;found {file.resolve()}, size={size}B&#34;)
                else:
                    logging.warning(
                        f&#34;path {file.resolve()} isn&#39;t a {self.filetype} file&#34;)

        # if no valid files were found, notify the user and exit. otherwise
        # report the total number of files found
        if not total:
            logging.error(&#34;no valid files found&#34;)
            exit(1)
        else:
            logging.debug(f&#34;found {total} total files&#34;)
        return files</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="dphon.corpus.JsonLinesCorpusLoader" href="#dphon.corpus.JsonLinesCorpusLoader">JsonLinesCorpusLoader</a></li>
<li><a title="dphon.corpus.PlaintextCorpusLoader" href="#dphon.corpus.PlaintextCorpusLoader">PlaintextCorpusLoader</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="dphon.corpus.CorpusLoader.filetype"><code class="name">var <span class="ident">filetype</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dphon.corpus.CorpusLoader.progress"><code class="name">var <span class="ident">progress</span> : rich.progress.Progress</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="dphon.corpus.JsonLinesCorpusLoader"><code class="flex name class">
<span>class <span class="ident">JsonLinesCorpusLoader</span></span>
</code></dt>
<dd>
<div class="desc"><p>Loads documents stored as lines in one or more .jsonl files.</p>
<p>Set up progress tracking.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class JsonLinesCorpusLoader(CorpusLoader):
    &#34;&#34;&#34;Loads documents stored as lines in one or more .jsonl files.&#34;&#34;&#34;

    filetype = &#34;.jsonl&#34;

    def __call__(self, paths: Iterable[str]) -&gt; Iterable[DocInfo_T]:
        &#34;&#34;&#34;Parse .jsonl files and yield document text and metadata.

        All provided paths will be searched, and globs will be expanded, e.g.
        /my/home/dir/*.jsonl will yield all jsonlines files in /my/home/dir/.

        Each .jsonl file is assumed to consist of lines where each line is a
        valid JSON object. The only required properties are &#34;id&#34;, a unique name
        for the document, and &#34;text&#34;, the text of the document itself. All
        other properties will be passed through to spaCy.

        Args:
            paths: Iterable of .jsonl file paths to load.

        Yields:
            A tuple of (contents, metadata) for each valid document found.
        &#34;&#34;&#34;

        # track progress
        files = self._check(paths)
        task = self.progress.add_task(
            &#34;indexing&#34;, filename=&#34;&#34;, total=len(files))

        # open each file and yield each line, with all properties except &#34;text&#34;
        # being passed as second element in tuple
        with self.progress:
            for file in files.keys():
                with jsonlines.open(file) as reader:
                    self.progress.update(task, filename=file.name)
                    for doc in reader:
                        meta = {k: v for k, v in doc.items() if k != &#34;text&#34;}
                        logging.debug(
                            f&#34;loaded doc \&#34;{doc[&#39;id&#39;]}\&#34; from {file.resolve()}&#34;)
                        yield doc[&#34;text&#34;].translate(OC_TEXT), meta
                    self.progress.advance(task)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="dphon.corpus.CorpusLoader" href="#dphon.corpus.CorpusLoader">CorpusLoader</a></li>
<li>abc.ABC</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="dphon.corpus.JsonLinesCorpusLoader.filetype"><code class="name">var <span class="ident">filetype</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dphon.corpus.JsonLinesCorpusLoader.progress"><code class="name">var <span class="ident">progress</span> : rich.progress.Progress</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="dphon.corpus.PlaintextCorpusLoader"><code class="flex name class">
<span>class <span class="ident">PlaintextCorpusLoader</span></span>
</code></dt>
<dd>
<div class="desc"><p>Loads documents stored as one or more .txt files.</p>
<p>Set up progress tracking.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PlaintextCorpusLoader(CorpusLoader):
    &#34;&#34;&#34;Loads documents stored as one or more .txt files.&#34;&#34;&#34;

    filetype = &#34;.txt&#34;

    def __call__(self, paths: Iterable[str]) -&gt; Iterable[DocInfo_T]:
        &#34;&#34;&#34;Load valid files and metadata and yield in order of size, desc.

        All provided paths will be searched, and globs will be expanded, e.g.
        /my/home/dir/*.txt will yield all plaintext files in /my/home/dir/.

        File metadata consists of the file&#39;s name, minus extension (the &#34;stem&#34;)
        and the file size on disk in bytes.

        Args:
            paths: Iterable of .txt file paths to load.

        Yields:
            A tuple of (contents, metadata) for each valid document found.
        &#34;&#34;&#34;

        # sort files by size, largest first, to speed up processing by spaCy
        files = self._check(paths)
        files_by_size = OrderedDict(sorted(files.items(),
                                           key=lambda f: f[1][&#34;size&#34;],
                                           reverse=True))

        # track progress
        task = self.progress.add_task(
            &#34;indexing&#34;, filename=&#34;&#34;, total=len(files))

        # open each file and yield contents with metadata as DocInfo_T
        with self.progress:
            for file, meta in files_by_size.items():
                self.progress.update(task, filename=file.name)
                with file.open(encoding=&#34;utf8&#34;) as contents:
                    logging.debug(
                        f&#34;loaded doc \&#34;{meta[&#39;id&#39;]}\&#34; from {file.resolve()}&#34;)
                    yield contents.read().translate(OC_TEXT), {&#34;id&#34;: meta[&#34;id&#34;]}
                    self.progress.advance(task)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="dphon.corpus.CorpusLoader" href="#dphon.corpus.CorpusLoader">CorpusLoader</a></li>
<li>abc.ABC</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="dphon.corpus.PlaintextCorpusLoader.filetype"><code class="name">var <span class="ident">filetype</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dphon.corpus.PlaintextCorpusLoader.progress"><code class="name">var <span class="ident">progress</span> : rich.progress.Progress</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="dphon" href="index.html">dphon</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="dphon.corpus.CorpusLoader" href="#dphon.corpus.CorpusLoader">CorpusLoader</a></code></h4>
<ul class="">
<li><code><a title="dphon.corpus.CorpusLoader.filetype" href="#dphon.corpus.CorpusLoader.filetype">filetype</a></code></li>
<li><code><a title="dphon.corpus.CorpusLoader.progress" href="#dphon.corpus.CorpusLoader.progress">progress</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dphon.corpus.JsonLinesCorpusLoader" href="#dphon.corpus.JsonLinesCorpusLoader">JsonLinesCorpusLoader</a></code></h4>
<ul class="">
<li><code><a title="dphon.corpus.JsonLinesCorpusLoader.filetype" href="#dphon.corpus.JsonLinesCorpusLoader.filetype">filetype</a></code></li>
<li><code><a title="dphon.corpus.JsonLinesCorpusLoader.progress" href="#dphon.corpus.JsonLinesCorpusLoader.progress">progress</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dphon.corpus.PlaintextCorpusLoader" href="#dphon.corpus.PlaintextCorpusLoader">PlaintextCorpusLoader</a></code></h4>
<ul class="">
<li><code><a title="dphon.corpus.PlaintextCorpusLoader.filetype" href="#dphon.corpus.PlaintextCorpusLoader.filetype">filetype</a></code></li>
<li><code><a title="dphon.corpus.PlaintextCorpusLoader.progress" href="#dphon.corpus.PlaintextCorpusLoader.progress">progress</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>